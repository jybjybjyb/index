---
layout: post
title: Net design
date: 2021-5-11
author: 
tags: [cv, note]
comments: true
toc: true
pinned: False
---

<!-- more -->

# 结构优化


## BN batch-normalization

## 添加残差连接

# Opt优化



# Loss函数

## 设计原则
1. 能够表示网络输出和待分割目标的相似程度
1. Loss的计算过程是可导的，可以进行误差反传

## Cross-Entropy (CE)
Cross-Entropy和它的一些改进说起，这一类Loss函数可以叫做Pixel-Level的Loss，因为他们都是把分割问题看做对每个点的分类

### wCE (weighted cross-entropy）
1. 对边界像素这些难学习的像素加大权重（pixel-weight）
1. 做类层面的加权（class-weight），比如对前景像素加大权重，背景像素减小权重，或者不同的类别按照其所占像素的比例，分配权重，占比小的权重大一些，占比大的权重小一些，解决样本不平衡的问题。

### Focal Loss
1. 使难分类样本权重大，易分类样本权重小。至于哪些是难分类样本哪些是易分类样本，都由网络的输出和真实的偏差决定。这就实现了**网络自适应调整**。类比我们学知识，难学习的内容，我们同样时间学的不好自己知道，我就会自觉的花更多精力去学习。以前的神经网络没有识别难易任务自动分配精力的方式，focal loss带来了这种自适应反馈。

### Dice Loss
1. Dice系数是分割效果的一个评判指标，其公式相当于预测结果区域和ground truth区域的交并比，所以它是把一个类别的所有像素作为一个整体去计算Loss的。因为Dice Loss直接把分割效果评估指标作为Loss去监督网络，不绕弯子，而且计算交并比时还忽略了大量背景像素，解决了正负样本不均衡的问题，所以收敛速度很快。


## 分割任务

**语义分割中一般用交叉熵来做损失函数，而评价的时候却使用IOU来作为评价指标**
1. 首先采用交叉熵损失函数，而非 dice-coefficient 和类似 IoU 度量的损失函数，一个令人信服的愿意是其梯度形式更优：
1. 直接采用 dice-coefficient 或者 IoU 作为损失函数的原因，是因为分割的真实目标就是最大化 dice-coefficient 和 IoU 度量. 而交叉熵仅是一种代理形式，利用其在 BP 中易于最大化优化的特点.
1. **Dice Loss** 训练误差曲线非常混乱，很难看出关于收敛的信息。尽管可以检查在验证集上的误差来避开此问题。

### Dics Loss

- 医学图像分割任务中常用的 Dice 损失函数
- Dice 相似系数（DSC，Dice Similarity Coefficient）
- 

### T-test

# 预处理


## Patch Size and Batch Size

在三维医学图像的处理中，显存不足是经常容易遇到的问题。而训练过程中，显存占用与模型的输入patch size，batch size以及网络的结构相关。然而，patch size越大，所需要的模型越大。因此，在抉择时，主要在patch size与batch size之间进行权衡。nnUNet中优先考虑patch size，保证模型能基于更多的信息来进行推理。但batch size最小值应该为2，需要保证训练过程中优化过程的鲁棒性。最后，在保证patch size的前提下，如果显存有多余的，再对应增加batch size。因为batch size大部分情况都比较小，所以之前固定设计中没有用BN而使用Instance Norm。

而最优patch size的决定，采用迭代的方式进行。将batch size先固定为2，然后设定一个较大的patch size初始值，再根据当前patch size来设计网络结构。之后根据显存占用情况，不断的迭代调整patch size。

## target spacing

target spacing指的是数据集在经过重采样之后，每张图像所具有的相同的spacing值，即每张图像的每个体素所代表的实际物理空间大小。
## 体积阈值化
为了减少假阳性，实验采用去除小连通域的方法进行后处理，将 3D 分割结果图中体积小于阈值的区域置为背景，阈值为分割结果图中的最大连通域的体积的三分之一。



# 集成 

![](https://pic2.zhimg.com/v2-e32f0053d7b8b8e0aa178658aaf16a15_r.jpg)


使用不同随机种子的学习网络F1，…F10 —— 尽管具有非常相似的测试性能 —— 被观察到与非常不同的函数相关联。实际上，使用一种著名的技术叫做集成(ensemble)，只需对这些独立训练的网络的输出进行无加权的平均，就可以在许多深度学习应用中获得测试时性能的巨大提升。(参见下面的图1。)这意味着单个函数F1，…F10必须是不同的。然而，为什么集成的效果会突然提高呢？另外，如果一个人直接训练(F1+⋯+F10)/10，为什么性能提升会消失？

# 知识蒸馏 

尽管集成在提高测试时性能方面非常出色，但在推理时间(即测试时间)上，它的速度会慢10倍：我们需要计算10个神经网络的输出，而不是一个。当我们在低能耗、移动环境中部署这样的模型时，这是一个问题。为了解决这个问题，提出了一种叫做知识蒸馏的开创性技术。也就是说，知识蒸馏只需要训练另一个单独的模型就可以匹配集成的输出。在这里，对猫图像的集成输出(也称为“dark knowledge”)可能是类似“80% cat + 10% dog + 10% car”，而真正的训练标签是“100% cat”

事实证明，经过训练的单个模型，在很大程度上，可以匹配10倍大的集成测试时的表现。

![](https://pic4.zhimg.com/v2-ccabe6da75bd07b9a9f023464612f907_b.jpg)


# 构架


## Mlp-mixer


下图 1 描述了 Mixer 的宏观架构，它以一系列图像块的线性投影（输入的形状为 patches × channels）作为输入，先将输入图片拆分为 patch，通过 Per-patch Fully-connected 将每个 patch 转换为 feature embedding，接着馈入 N 个 Mixer Layer，最后通过 Fully-connected 进行分类。

![](https://pic2.zhimg.com/v2-391f4f65b4e534dd56b9662a2b4e20c9_r.jpg)

- Mixer 架构采用两种不同类型的 MLP 层：channel-mixing MLP 和 token-mixing MLP。

- channel-mixing MLP 允许不同通道之间进行通信，token-mixing MLP 允许不同空间位置（token）之间进行通信。这两种类型的层交替执行以促进两个维度间的信息交互。

- Mixer 架构可以看做是一个特殊的 CNN，使用 1×1 卷积进行 channel mixing，同时全感受野和参数共享的的单通道深度卷积进行 token mixing。

### 设计思想

- Mixer 架构的设计思想是**清楚地**将按位置（channel-mixing）操作 (i) 和跨位置（token-mixing）操作 (ii) 分开，两种操作都通过 MLP 来实现。

- Mixer 由大小相同的多个层组成。每个层由 2 个 MLP 块组成，其中，第一个块是 token-mixing MLP 块，第二个是 channel-mixing MLP 块。每个 MLP 块包含两个全连接层，以及一个单独应用于其输入数据张量的每一行的非线性层。

- Mixer 中的每个层（初始 patch 投影层除外）都采用相同大小的输入，这种「各向同性（isotropic）」的设计与使用固定宽度的 Transformer 或其他域中的深度 RNN 大致相似。

- 这不同于大多数具有金字塔结构的 CNN，即较深的层具有较低分辨率的输入，但是有较多通道（channel）。

- 除了 MLP 层，Mixer 还使用其他标准架构组件：跳远连接（skip-connection）和层归一化。此外，和 ViT 不同，Mixer 不使用位置嵌入，因为 token-mixing MLP 对输入 token 的顺序很敏感，因此能够学会表征位置。最后，Mixer 将标准分类头与全局平均池化层配合使用，随后使用线性分类器。




### 1*1 卷积

![](https://pic4.zhimg.com/80/v2-cf42a8eb42fa902347a619c6e4878840_1440w.jpg?source=3af55fa1)

1. 调节通道数
1. 增加非线性，可以在保持特征图尺度不变的（即不改变）的前提下大幅增加非线性特性
1. 跨通道信息，通道间的信息交互。
1. 减少参数，

## Transformer


自注意力通过使用所有位置之间的成对亲和力来计算特征的加权总和，以捕获单个样本内的长期依赖性，从而更新每个位置的特征。

![](https://pic3.zhimg.com/v2-a1d3c1ac443534c7f5a1f5693d4ea04e_r.jpg)



### ViT（vision transformer）
Google在2020年
1. 直接把图像分成固定大小的patchs，然后通过线性变换得到patch embedding，这就类比NLP的words和word embedding
1. 由于transformer的输入就是a sequence of token embeddings，所以将图像的patch embeddings送入transformer后就能够进行特征提取从而分类了